{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\n\ndef display(*dfs):\n    for df in dfs:\n        IPython.display.display(df)\n        \n## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time df = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv', engine='c')\n# labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\ndf_test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\nspecs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\n\ndf = reduce_mem_usage(df)\n# labels = reduce_mem_usage(labels)\ndf_test = reduce_mem_usage(df_test)\nspecs = reduce_mem_usage(specs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_counter = pd.read_feather('/kaggle/input/temp-ds-bowl-2019/df_counter_ini')\n# df_counter = pd.read_feather('/kaggle/input/temp-ds-bowl-2019/df_counter')\nlabels = pd.read_feather('/kaggle/input/temp-ds-bowl-2019/labels_created')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all_users = pd.read_pickle('/kaggle/input/temp-ds-bowl-2019/all_users.pkl')\n# all_users.installation_id.unique().shape, labels.installation_id.unique().shape\n\n# test_all_users = pd.read_pickle('/kaggle/input/temp-ds-bowl-2019/test_all_users.pkl')\n# test_all_users.installation_id.unique().shape, test_all_users.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part I - Create all_users\n## One user"},{"metadata":{"trusted":true},"cell_type":"code","source":"#user_id, user = next(iter(df.groupby('installation_id')))\nuser_id = '8e44d2de' # 'f10d8174'#'ea49ea9c'#'29d1aaee' # '3f0dca37'\nuser = df[df.installation_id == user_id].copy()\n\ntotall_attempts = labels[labels.installation_id == user_id].total_attempts.sum()\nprint(totall_attempts)\n\ntotall_assessments  = labels[labels.installation_id == user_id].shape[0]\ntotall_assessments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user['timestamp'] = pd.to_datetime(user['timestamp'])\nprint(user.shape)\nuser.sort_values(by='timestamp').head()\n\nuser['attempt'] = ((user.type == 'Assessment') &\n                       (((user.event_code == 4100) & (user.title != 'Bird Measurer (Assessment)')) |\n                        ((user.event_code == 4110)&(user.title == 'Bird Measurer (Assessment)')) )\n                   ).astype('int8')\n#attempt_idx = user[user.attempt == 1].index\nassert user.attempt.sum() == totall_attempts\n\nuser['correct'] = 0\nuser.loc[user.attempt == 1, 'correct'] = user[user.attempt == 1].event_data.str.contains('\"correct\":true').astype('int8')\n#user","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def current_attempt_save(attempt, user_temp, session):\n    temp = user_temp.copy()\n    attempt['total_accuracy'] = np.mean(temp['total_accuracy']) \\\n                                   if isinstance(temp['total_accuracy'], list) else -1\n    attempt['total_accuracy_groups'] = np.mean(temp['total_accuracy_groups']) \\\n                                          if isinstance(temp['total_accuracy_groups'], list) else -1        \n    attempt['curr_attempt_world'] = session.world.iloc[0]\n    attempt['curr_attempt_title'] = session.title.iloc[0]\n    attempt['curr_attempt_start_time'] = session.timestamp.iloc[0]\n    attempt['curr_attempt_duration'] = attempt['time_start'] - attempt['curr_attempt_start_time']\n        \n    return attempt\n\ndef current_world_save(attempt, user_temp, world):\n    # current WORLD - write all previous info in current world\n    features = [x for x in user_temp.keys() if world in str(x)]\n    temp = defaultdict(int)\n    temp.update({k.replace(world, 'world'):user_temp[k] for k in features})\n    f = [x.replace(world, 'world') for x in features if 'unique' in x]\n    assert len(f) <= 4\n    temp.update({k: len(set(temp[k])) for k in f})\n    temp['world_accuracy'] = np.mean(temp['world_accuracy']) \\\n                             if isinstance(temp['world_accuracy'], list) else -1\n    temp['world_accuracy_groups'] = np.mean(temp['world_accuracy_groups']) \\\n                                    if isinstance(temp['world_accuracy_groups'], list) else -1\n\n    f = [x for x in features if 'game_time' in x]\n    temp['world_total_game_time'] = np.sum([user_temp[x] for x in f])\n    f = [x for x in features if 'event_count' in x]\n    temp['world_total_event_count'] = np.sum([user_temp[x] for x in f])\n    f = [x for x in features if 'n_game_session' in x]\n    temp['world_total_n_game_session'] = np.sum([user_temp[x] for x in f])\n    attempt.update(temp)\n    \n    return attempt\n\n\ndef current_title_save(attempt, user_temp, title):\n    # current TITLE - write all previous info in attempts with the same title\n    features = [x for x in user_temp.keys() if title in str(x)]\n    temp = defaultdict(int)\n    temp.update({k.replace(title, 'title'):user_temp[k] for k in features})\n    temp['title_accuracy'] = np.mean(temp['title_accuracy']) \\\n                             if isinstance(temp['title_accuracy'], list) else -1\n    temp['title_accuracy_groups'] = np.mean(temp['title_accuracy_groups']) \\\n                                    if isinstance(temp['title_accuracy_groups'], list) else -1\n    attempt.update(temp)\n    \n    return attempt\n\ndef create_sample(user_data, user_temp, session):\n    attempt = user_data.copy()\n    title = session.title.iloc[0]\n    world = session.world.iloc[0]\n    \n    attempt = current_attempt_save(attempt, user_temp, session)\n    attempt = current_world_save(attempt, user_temp, world)\n    attempt = current_title_save(attempt, user_temp, title)\n\n    # to labels\n    attempt['n_correct'] = session.correct.sum()\n    attempt['n_incorrect'] = session.attempt.sum() - attempt['n_correct']\n\n    # TOTAL info\n    for t in ['Clip', 'Game', 'Activity', 'Assessment']:\n        attempt['total_' + t +'_unique'] = len(set(attempt['total_' + t +'_unique'])) \\\n                                                if isinstance(attempt['total_' + t +'_unique'], list) \\\n                                                and len(attempt['total_' + t +'_unique']) >0 else 0\n\n    return attempt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_to_group = {1: 3, 0.5: 2, 0: 0}\n\ndef get_common_data(session, user_data, user_temp, user_results, test=False):\n    \"\"\"\n    params: \n        session: DataFrame - one session form groupby('game_session')\n        user_data: dict - dict with data info about user. Accumulate all infor for user though attempts.\n    return:\n        user_results: list - list of dictionaries, one for each attempt of one user\n    \"\"\"\n    data_type = session.type.iloc[0]\n    world = session.world.iloc[0]\n    template = world +'_'+ data_type\n    user_temp[template+'_unique'] = user_temp.get(template+'_unique', [])\n    user_data['total_' + data_type+'_unique'] = user_data.get('total_' + data_type+'_unique', [])\n    \n    if data_type == 'Assessment':\n        if session.attempt.sum() >= 1 or test:  \n            # create sample for train set\n            attempt = create_sample(user_data, user_temp, session)\n            user_results.append(attempt)\n\n        #  ======= Save info for future attempt ====== title = session.title.iloc[0]       \n        # current title - CALCULATE (accumulate) all previous info in attempts with the same title\n        n_correct = session.correct.sum()\n        n_incorrect = session.attempt.sum() - n_correct\n        \n        title = session.title.iloc[0]\n        user_temp[title + '_n_assessments'] += 1\n        user_temp[title + '_n_assess_with_attempt'] += 1 if session.attempt.sum() > 0 else 0\n        user_temp[title + '_n_attempts'] += session.attempt.sum()\n        user_temp[title + '_n_correct'] += n_correct\n        user_temp[title + '_n_incorrect'] += n_incorrect\n        user_temp[title + '_n_unfinished'] += 0  if session.attempt.sum() > 0 else 1\n        \n        if session.attempt.sum() != 0:\n            accuracy = session.correct.sum()/ session.attempt.sum()\n            user_temp[title + '_accuracy'] = user_temp.get(title+'_accuracy_groups', []) +[accuracy]\n            group = accuracy_to_group.get(accuracy, 1)\n            user_temp[title+'_accuracy_groups'] = user_temp.get(title+'_accuracy_groups', []) +[group]\n\n        user_temp[title + '_event_count'] += session.shape[0]\n        user_temp[title + '_game_time'] += session.game_time.max()\n        \n        #print(session.shape[0], user_temp[title + '_event_count'])\n        # Currect attempts - to future\n        user_temp[world+'_n_correct'] += n_correct\n        user_temp[world+'_n_incorrect'] += n_incorrect\n        user_data['total_n_correct'] += n_correct\n        user_data['total_n_incorrect'] += n_incorrect\n        \n        if n_correct + n_incorrect != 0:\n            accuracy = n_correct/(n_correct+n_incorrect)\n            group = accuracy_to_group.get(accuracy, 1)\n            \n            user_temp[world+'_accuracy'] = user_temp.get(world+'_accuracy', []) +[accuracy]\n            user_temp[world+'_accuracy_groups'] = user_temp.get(world+'_accuracy_groups', []) +[group]\n            user_temp['total_accuracy'] = user_temp.get('total_accuracy', []) +[accuracy]\n            user_temp['total_accuracy_groups'] = user_temp.get('total_accuracy_groups', []) +[group]        \n        \n    event_code_counts = session['event_code'].value_counts()\n    for i, j in zip(event_code_counts.index, event_code_counts.values):\n        user_data[i] = user_data.get(i,0) + j\n        \n    # add common info, include attempt info for next study\n    user_temp[template+'_unique'].append(session.title.iloc[0])\n    user_temp[template+'_n_game_session'] += 1\n    user_temp[template+'_event_count'] += session.shape[0]\n    \n    template_total = 'total_' + data_type\n    user_data[template_total+'_unique'].append(session.title.iloc[0])\n    user_data[template_total+'_n_game_session'] += 1\n    user_data[template_total+'_event_count'] += session.shape[0]\n    \n    if data_type != 'Clip':\n        user_temp[template+'_game_time'] += session.game_time.max()\n        user_data[template_total+'_game_time'] += session.game_time.max()\n        user_data['total_game_time'] += session.game_time.max()\n        \n    user_data['total_' + data_type] += 1\n    user_data['total_n_game_session'] += 1\n    user_data['total_event_count'] += session.shape[0]\n    \n        \n        \n    return user_results\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \nuser_results = []\n\nfrom collections import defaultdict\nuser_data, user_temp = defaultdict(int), defaultdict(int)\nuser_data['installation_id'] = user.installation_id.iloc[0]\nuser_data['time_start'] = user.timestamp.iloc[0]\n\nfor i, session in user.groupby('game_session', sort=False):\n    #print(user_data)\n    get_common_data(session, user_data, user_temp, user_results)\n    \ntt = pd.DataFrame(user_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt[tt.curr_attempt_start_time == '2019-09-12 23:56:55.085000+00:00'].title_event_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total: for all users"},{"metadata":{},"cell_type":"markdown","source":"### Info for last attemp"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_all_users(df, test=False):\n    global labels\n    all_users = pd.DataFrame()\n    \n    if test: labels = df  # all unique users with attemptions; for test - all users\n    for n,user_id in enumerate(labels.installation_id.unique()):\n        # print(n, user_id)\n        user = df[df.installation_id == user_id].copy()\n        user['timestamp'] = pd.to_datetime(user['timestamp'])\n        user.sort_values(by='timestamp', inplace=True)\n\n        user['attempt'] = ((user.type == 'Assessment') &\n                           (((user.event_code == 4100) & (user.title != 'Bird Measurer (Assessment)')) |\n                            ((user.event_code == 4110)&(user.title == 'Bird Measurer (Assessment)')) )\n                       ).astype('int8')\n\n        user['correct'] = 0\n        user.loc[user.attempt == 1, 'correct'] = user[user.attempt == 1]\\\n                                                .event_data.str.contains('\"correct\":true').astype('int8')\n\n        user_results = []\n\n        user_data, user_temp = defaultdict(int), defaultdict(int)\n        user_data['installation_id'] = user.installation_id.iloc[0]\n        user_data['time_start'] = user.timestamp.iloc[0]\n        \n        for i, session in user.groupby('game_session', sort=False):\n            get_common_data(session, user_data, user_temp, user_results, test=test)\n\n        temp = all_users.shape\n        all_users = pd.concat((all_users,pd.DataFrame(user_results)), ignore_index=True, sort=False)\n        \n        assert all_users.shape > temp, user_id\n#         display(all_users)\n#         input()\n    \n    return all_users","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time all_users = create_all_users(df)\n\nprint(all_users.shape, all_users.installation_id.unique().shape)\nall_users.columns = all_users.columns.astype(str)\n# all_users.to_pickle('all_users.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_users[all_users.curr_attempt_start_time == '2019-09-12 23:56:55.085000+00:00'][title_columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.installation_id.unique().shape, df_test.installation_id.unique().shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time test_all_users = create_all_users(df_test, test=True)\n\n# take only last assessment\ntest_all_users = test_all_users.groupby('installation_id', sort=False, as_index=False)\\\n                            .agg([lambda x: x.iloc[-1]])\ntest_all_users.columns = [x[0] for x in test_all_users.columns]\ntest_all_users.reset_index(inplace=True)\n\nprint(test_all_users.shape, test_all_users.installation_id.unique().shape)\ntest_all_users.columns = test_all_users.columns.astype(str)\n# test_all_users.to_pickle('test_all_users.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part II - preprocess train data\n## Features names"},{"metadata":{"trusted":true},"cell_type":"code","source":"c = test_all_users.columns\n# c = all_users.columns\nworld_columns = [x for x in c if 'world' in x and 'curr' not in x]\ntitle_columns = [x for x in c if 'title' in x and 'curr' not in x]\ncurrent_columns = [x for x in c if 'curr' in x] + ['installation_id', 'time_start', 'n_correct', 'n_incorrect', \n                                                   'total_n_game_session', 'total_event_count', 'total_game_time',\n                                                   'total_n_correct', 'total_n_incorrect', \n                                                   'total_accuracy', 'total_accuracy_groups']\ntotal_columns = [x for x in c if 'total' in x and 'world' not in x and x not in current_columns]\nevent_columns = [x for x in c if x.isdigit()]\nall_columns = world_columns+title_columns+current_columns+total_columns+event_columns\nassert c.shape[0] == len(all_columns), (c.shape[0] ,len(all_columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill NAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_all_users.fillna(0., inplace=True)\nall_users.fillna(0., inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Work with time"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_time(test_all_users):\n    time_columns = ['time_start', 'curr_attempt_start_time'] \n    for t in time_columns:\n        test_all_users[t+'_month'] = test_all_users[t].dt.month\n        test_all_users[t+'_day'] = test_all_users[t].dt.day\n        test_all_users[t+'_hour'] = test_all_users[t].dt.hour\n        test_all_users[t+'_dayofweek'] = test_all_users[t].dt.dayofweek\n        test_all_users[t+'_month'] = test_all_users[t].dt.month\n        test_all_users[t+'_quarter'] = test_all_users[t].dt.quarter\n\n    t =  'curr_attempt_duration'\n    test_all_users[t+'seconds'] = -test_all_users[t].dt.total_seconds()\n    test_all_users[t+'hours'] = -test_all_users[t].dt.total_seconds()/60/60\n    \n    return test_all_users\n    \n    \ndef create_means(all_users, temp, t=''):\n    if t != '': t ='_' + t\n    if t != '_Clip':\n        all_users[temp+t+'_game_time_mean'] =  all_users[temp+t+'_game_time']/ \\\n                                                    all_users[temp+t+'_n_game_session']\n        all_users[temp+t+'_event_time_mean'] =  all_users[temp+t+'_game_time']/ \\\n                                                    all_users[temp+t+'_event_count']\n            \n    all_users[temp+t+'_event_mean'] = all_users[temp+t+'_event_count']/ \\\n                                          all_users[temp+t+'_n_game_session']\n    return all_users\n\n\ndef preprocess_data(all_users):\n    for temp in ['world', 'total']:\n        for t in ['Clip', 'Game', 'Assessment', 'Activity', 'total']:\n            if temp=='total' and t=='total': continue\n            all_users = create_means(all_users, temp, t)\n        \n        \n    all_users['title_game_time_mean'] = all_users['title_game_time']/ all_users['title_n_assessments']                                            \n    all_users['title_event_time_mean'] = all_users['title_game_time']/ all_users['title_event_count']                                            \n    all_users['title_event_mean'] = all_users['title_event_count']/ all_users['title_n_assessments']\n    \n    all_users = preprocess_time(all_users)\n    all_users = create_means(all_users, temp='total', t='')\n        \n    all_users.fillna(0., inplace=True)               \n        \n    return all_users","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_all_users = preprocess_data(test_all_users)\nall_users = preprocess_data(all_users)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_all_users.shape, all_users.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = test_all_users.columns\nworld_columns = [x for x in c if 'world' in x and 'curr' not in x]\ntitle_columns = [x for x in c if 'title' in x and 'curr' not in x]\ncurrent_columns = [x for x in c if 'curr' in x] + ['installation_id', 'time_start', 'n_correct', 'n_incorrect', \n                                                   'total_n_game_session', 'total_event_count', 'total_game_time',\n                                                   'total_n_correct', 'total_n_incorrect', \n                                                   'total_accuracy', 'total_accuracy_groups',\n                                                   'total_game_time_mean', 'total_event_time_mean', 'total_event_mean',\n                                                   'time_start_month', 'time_start_day', 'time_start_hour',\n                                                   'time_start_dayofweek', 'time_start_quarter']\ntotal_columns = [x for x in c if 'total' in x and 'world' not in x and x not in current_columns]\nevent_columns = [x for x in c if x.isdigit()]\nall_columns = world_columns+title_columns+current_columns+total_columns+event_columns\nassert c.shape[0] == len(all_columns), (c.shape[0] ,len(all_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_all_users.to_pickle('test_all_users.pkl')\nall_users.to_pickle('all_users.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_users[all_users.curr_attempt_start_time == '2019-09-12 23:56:55.085000+00:00'][title_columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# try parralel\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from joblib import Parallel, delayed\nfrom tqdm import tqdm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_attempt_and_correct_features(df_test):\n    df_test['attempt'] = ((df_test.type == 'Assessment') &\n                       (((df_test.event_code == 4100) & (df_test.title != 'Bird Measurer (Assessment)')) |\n                        ((df_test.event_code == 4110)&(df_test.title == 'Bird Measurer (Assessment)')) )\n                   ).astype('int8')\n\n    df_test['correct'] = 0\n    df_test.loc[df_test.attempt == 1, 'correct'] = df_test[df_test.attempt == 1]\\\n                                            .event_data.str.contains('\"correct\":true').astype('int8')\n    df_test.timestamp = pd.to_datetime(df_test.timestamp)\n\n    return df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = create_attempt_and_correct_features(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_one_user(user, test):\n    user['timestamp'] = pd.to_datetime(user['timestamp'])\n    user.sort_values(by='timestamp', inplace=True)\n\n    user_results = []\n    user_data, user_temp = defaultdict(int), defaultdict(int)\n    user_data['installation_id'] = user.installation_id.iloc[0]\n    user_data['time_start'] = user.timestamp.iloc[0]\n\n    for i, session in user.groupby('game_session', sort=False):\n        get_common_data(session, user_data, user_temp, user_results, test=test)\n\n    return user_results\n\n\ndef group_by_user(labels, df):\n    for n,user_id in enumerate(labels.installation_id.unique()):\n        user = df[df.installation_id == user_id].copy()\n        yield user\n    \n\ndef create_all_users_parallel(df, test=False):\n    global labels\n    all_users = pd.DataFrame()\n    \n    if test: labels = df  # all unique users with attemptions; for test - all users\n    \n    \n    res = Parallel(n_jobs=-1, backend='threading', verbose=10)(delayed(create_one_user)(user, test=test)\n                                                        for user in group_by_user(labels, df))\n    all_users = []\n    for r in res:\n        for r1 in r:\n            all_users.append(r1)\n    #for user in group_by_user(labels, df):\n    #    user_results = create_one_user(user, test=test)\n        \n    #    all_users = pd.concat((all_users,pd.DataFrame(user_results)), ignore_index=True, sort=False)\n\n    \n    return pd.DataFrame(all_users)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time t2 = create_all_users_parallel(df_test, test=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t[t.installation_id == '01bc6cb6']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_all_users[test_all_user.installation_id == '01bc6cb6']","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}
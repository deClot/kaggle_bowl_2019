{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\n\ndef display(*dfs):\n    for df in dfs:\n        IPython.display.display(df)\n\n# display(df1, df2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%time df = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv', engine='c')\nlabels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = reduce_mem_usage(df)\nlabels = reduce_mem_usage(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape, labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Format and make date / hour features\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\n# df['date'] = df['timestamp'].dt.date\n# df['hour'] = df['timestamp'].dt.hour\n# df['weekday_name'] = df['timestamp'].dt.weekday_name\n# # Same for test\n# # test['timestamp'] = pd.to_datetime(test['timestamp'])\n# # test['date'] = test['timestamp'].dt.date\n# # test['hour'] = test['timestamp'].dt.hour\n# # test['weekday_name'] = test['timestamp'].dt.weekday_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_subm = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\nsample_subm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\nspecs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train = df.copy()\n# df = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_label_all(df, labels=None):\n#     id_unique = labels.installation_id.unique()\n#     print('Numer of unique installation_id:', id_unique.shape[0])\n    \n    if labels is not None:\n        # labels_part = labels[labels.installation_id.isin(id_unique[:n])]\n        labels_part = labels.copy()\n        \n    # df_ids = df[df.installation_id.isin(id_unique[:n])].reset_index()\n    df_ids = df.reset_index()\n    assert df_ids.shape[0] == df.shape[0]\n    \n    extracted_event = df_ids[df_ids.event_data.str.contains('correct')]\n    extracted_event['correct'] = np.where(extracted_event.event_data.str.find('\"correct\":true')!=-1, True, False)\n    print('Number of samples with \"correct\" in event_data:', extracted_event.shape)\n\n    df_ids.loc[:, 'correct'] = np.nan\n    df_ids.update(extracted_event.correct)\n    del extracted_event\n    print('Number of unique ids in train set:', df_ids.installation_id.unique().shape, \n          'Shape of data:', df_ids.shape)\n    \n    index_for_correct = ~df_ids.correct.isna()\n#     df_ids[index_for_correct]\n\n    df_counter = df_ids[index_for_correct]\n    df_counter_wt_BM = df_counter[(df_counter.event_code == 4100) & (df_counter.title.str.find('Bird Measurer')==-1)]\n    df_counter_BM = df_counter[(df_counter.event_code == 4110) & (df_counter.title.str.find('Bird Measurer')!=-1)]\n\n    df_counter_ini = df_counter_wt_BM.append(df_counter_BM)\n    df_counter = df_counter_ini.groupby('game_session').agg({'correct': 'sum',\n                                                         'event_code': 'count',\n                                                         'installation_id': lambda x: x.iloc[0],\n                                                         'title': lambda x: x.iloc[0]})\n\n    df_counter['accuracy'] = df_counter.correct/df_counter.event_code\n    if labels is not None:\n        df_check = df_counter.merge(labels_part, on='game_session', how='left')\n    \n    return df_counter_ini, df_counter, df_check\n\n# df_counter_ini, df_counter, df_check = create_label_all(df, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"download_or_not = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if download_or_not:\n    print('Reading feathers')\n    df_counter_ini = pd.read_feather('/kaggle/input/ds-bowl-labels/df_counter_ini')\n    df_counter = pd.read_feather('/kaggle/input/ds-bowl-labels/df_counter')\nelse: \n    print('Calculating')\n    df_counter_ini, df_counter, df_check = create_label_all(df, labels)\n    \n    print('Writing to feather')\n    df_counter.correct = df_counter.correct.astype(int)\n    df_counter_ini.reset_index().to_feather('df_counter_ini')\n    df_counter.reset_index().to_feather('df_counter')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import json \n# extracted_event_data = pd.io.json.json_normalize(df_ids.event_data.apply(json.loads))\n# print(extracted_event_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'New lables:', df_counter.shape[0] - labels.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    df_error = df_check[(np.abs(df_check.accuracy_x-df_check.accuracy_y) > 0.001) & \n                         (~df_check.accuracy_y.isna())]\n    print('Number of error calculated labels:', df_error.shape[0])\n    #df_error\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data study"},{"metadata":{},"cell_type":"markdown","source":"## Check ids which never took assessments"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('# unique ids with assessment:', df.installation_id.unique().shape)\nprint('# unique ids in train:', df_counter.installation_id.unique().shape)\nprint('# unique ids in train_labels:', labels.installation_id.unique().shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create initial labels (like in train_labels file)"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(labels, df_counter, df_counter_ini)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_counter['num_incorrect'] = df_counter.event_code - df_counter.correct\ndf_counter.rename(columns={'correct': 'num_correct', 'event_code': 'total_attempts'}, inplace=True)\ndf_counter.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In train_labelsfiles there ate not sample with 2 ore more num_correct, whereas in our data there are such kind of samples. For initial labels files withh use only samples like in train_labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(labels[labels.num_correct > 1], df_counter[df_counter.num_correct > 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_counter_download = df_counter.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_counter = df_counter[df_counter.num_correct <= 1]\nprint(df_counter_download.shape, df_counter.shape)\ndf_counter.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_group_map = {1: 3, 0.5: 2, 0: 0}\ndf_counter['accuracy_group'] = df_counter.accuracy.apply(lambda x: acc_group_map[x] if x >=0.5 or x ==0 else 1)\ndf_counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_new_labels(df_coutern, labels=labels):\n    print('# of new labels:', df_counter.shape[0] - labels.shape[0])\n    assert labels.installation_id.unique().shape[0] == np.isin(labels.installation_id.unique(), \n                                                           df_counter.installation_id.unique()).sum()\n    assert labels.game_session.unique().shape[0] == np.isin(labels.game_session.unique(), \n                                                           df_counter.game_session.unique()).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_new_labels(df_counter)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How is new samples looks like ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sequence_correct_attempt_by_game_session(df_counter_ini=df_counter_ini):\n    df_counter_ini['correct_str'] = df_counter_ini.correct.astype(int).astype(str)\n    to_add = df_counter_ini.groupby('game_session').agg({'correct_str': 'sum'})\n    return to_add","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_counter.reset_index(inplace=True)\nto_add = sequence_correct_attempt_by_game_session(df_counter_ini)\nassert to_add.shape[0], df_counter_download.shape[0]\n\ndf_counter_download = df_counter_download.merge(to_add, how='left', on='game_session')\ndf_counter = df_counter.merge(to_add, how='left', on='game_session')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df_counter.merge(labels, how='left', on='game_session')\ndf_counter[temp.installation_id_y.isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef find_unnormal_sequences(df):\n    template = r'^[01]0*$' # start with 0or1 and then only 0s\n    df.correct_str = df_counter.correct_str.str[::-1] # reverse string; now last attempt is on 0 index\n    #print(df.head())\n    return df[~df.correct_str.str.contains(template, regex=True)].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = find_unnormal_sequences(df_counter[temp.installation_id_y.isna()])\ndf_counter.loc[idx]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are samples when after correct attemp were took other attemptions with wrong answer. We don't know now how to calculate sych labels  and for now we delet it to get most closest to train_label set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_counter = df_counter[(~df_counter.index.isin(idx))]\ndf_counter.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_new_labels(df_counter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_counter.reset_index(inplace=True, drop=True)\ntemp = df_counter.merge(labels, how='left', on='game_session')\ntemp = df_counter[temp.installation_id_y.isna()]\ntemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_to_add = df_counter_ini.groupby('game_session').agg({'timestamp': lambda x: x.iloc[-1]})\ntemp.merge(time_to_add, how='left', on='game_session').timestamp.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.merge(time_to_add, how='left', on='game_session').timestamp.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No time difference in new lables and train_labels. For now we will use these labels with new created."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_use = ['game_session', 'installation_id', 'title',\n                  'num_correct', 'num_incorrect', 'total_attempts',\n                  'accuracy', 'accuracy_group', 'correct_str']\ndf_counter = df_counter[columns_to_use]\ndisplay(df_counter, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_counter.to_feather('labels_created_ini')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}